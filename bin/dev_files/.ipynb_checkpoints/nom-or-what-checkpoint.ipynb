{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the environment\n",
    "import os\n",
    "import re\n",
    "# from os.path import join, isfile, splitext\n",
    "# from os import listdir\n",
    "# from IPython.core.display import display, HTML\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "from nomorwhat import *\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "macro_config_file = 'macros.yml'\n",
    "# input_file = 'test_input.txt'\n",
    "input_file = 'test_100_input.txt'\n",
    "input_file = 'test_500_input.txt'\n",
    "input_file = 'test_1000_input.txt'\n",
    "# output_file = 'test_output.txt'\n",
    "output_file = 'test_100_output.txt'\n",
    "output_file = 'test_500_output.txt'\n",
    "output_file = 'test_1000_output.txt'\n",
    "# orig_annot_file = 'test_full_annot.txt'\n",
    "orig_annot_file = 'test_100_full_annot.txt'\n",
    "orig_annot_file = 'test_500_full_annot.txt'\n",
    "orig_annot_file = 'test_1000_full_annot.txt'\n",
    "# merged_output_file = 'test_merged_output.txt'\n",
    "merged_output_file = 'test_100_merged_output.txt'\n",
    "merged_output_file = 'test_500_merged_output.txt'\n",
    "merged_output_file = 'test_1000_merged_output.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ligeti/bin/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# reading macros\n",
    "with open(macro_config_file, 'r') as fin:\n",
    "    macros = yaml.load(fin)\n",
    "# my_sentences = readtext(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_macro(macro_name, anal):\n",
    "    macro_res = False\n",
    "    # print(macro_name, anal)\n",
    "    if macros['macros'][macro_name]['type'] == 'list':\n",
    "        if anal[0] in macros['macros'][macro_name]['value']:\n",
    "            macro_res = True\n",
    "        else:\n",
    "            macro_res = False\n",
    "    elif macros['macros'][macro_name]['type'] == 'regex':\n",
    "        if macros['macros'][macro_name]['regexp_type'] == 'search':\n",
    "            macro_res = re.search(macros['macros'][macro_name]['value'], anal[2])\n",
    "        else:\n",
    "            pass\n",
    "    elif macros['macros'][macro_name]['type'] == 'ends':\n",
    "        macro_res = anal[2].endswith(macros['macros'][macro_name]['value'])\n",
    "    elif macros['macros'][macro_name]['type'] == 'complex':\n",
    "        if macros['macros'][macro_name]['compl_type'] == 'and': \n",
    "            all_true = True\n",
    "            for macro in macros['macros'][macro_name]['sub_macros']:\n",
    "                if not check_macro(macro,anal):\n",
    "                    all_true = False\n",
    "                    break\n",
    "            macro_res = all_true\n",
    "        elif macros['macros'][macro_name]['compl_type'] == 'or':\n",
    "            one_true = False\n",
    "            for macro in macros['macros'][macro_name]['sub_macros']:\n",
    "                if check_macro(macro,anal):\n",
    "                    one_true = True\n",
    "                    break\n",
    "            macro_res = one_true\n",
    "    elif macros['macros'][macro_name]['type'] == 'neg':\n",
    "        macro_res = not check_macro(macros['macros'][macro_name]['sub_macro'],anal)\n",
    "            \n",
    "    return macro_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ugyesvagyez\n",
      "ugyesvagy\n",
      "ugyesvagy\n",
      "ugyesvagyte\n",
      "ugyesvagy\n",
      "ugyesvagy\n",
      "ugyI\n",
      "ugyesvagy\n",
      "na\n"
     ]
    }
   ],
   "source": [
    "#macro_name = 'nu_mn'\n",
    "#macros['macros'][macro_name]\n",
    "\n",
    "if check_macro('not_gen', ['ez', 'ez', 'FN_NM.NOM']):\n",
    "    print(\"ugyesvagyez\")\n",
    "if check_macro('NPMod', ['szép', 'szép', 'MN.NOM']):\n",
    "    print(\"ugyesvagy\")\n",
    "if check_macro('NOM', [\"almák\", 'alma', 'FN.PL.NOM']):\n",
    "    print(\"ugyesvagy\")\n",
    "if check_macro('not_kop_v', ['válaszolt', 'válaszol', 'IGE.Me3']):\n",
    "    print(\"ugyesvagyte\")\n",
    "if check_macro('def_art', ['a', 'a', 'DET']):\n",
    "    print('ugyesvagy')\n",
    "if not check_macro('def_art', ['az', 'az', 'FN_NM.NOM']):\n",
    "    print('ugyesvagy')\n",
    "if check_macro('full_stop', ['.', '.', 'SPUNCT']):\n",
    "    print('ugyI')\n",
    "if not check_macro('Adj_tree', ['szépek', 'szép', 'MN.PL.NOM']):\n",
    "    print('ugyesvagy')\n",
    "\n",
    "if check_macro('NPMod', ['1848_49-es', '1848_49-es', 'MN.NOM']):\n",
    "    print(\"na\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NUM_rules(window, curr_POS):\n",
    "    first_right_word, first_right_lemma, first_right_annot = window[0]\n",
    "    second_right_word, second_right_lemma, second_right_annot = window[1]\n",
    "    \n",
    "    if re.search(\"FN|SZN|MN|NU\", first_right_annot): # if the next token is a nominal, or a postposition, the word gets a \"none\"\n",
    "        curr_POS = curr_POS.replace('NOM', 'semmi')\n",
    "        \n",
    "    elif check_macro('not_kop_v', window[0]): # if the next token is verb, but not a copula, the word is a nominative\n",
    "        curr_POS = curr_POS.replace('NOM', 'nom')\n",
    "        \n",
    "    elif check_macro('def_art', window[0]): # or re.search('HA', first_right_annot): # if the next token is a definite article or an adverb, the word is a nominative\n",
    "        curr_POS = curr_POS.replace('NOM', 'nom')\n",
    "\n",
    "        \n",
    "    else:\n",
    "        curr_POS = curr_POS.replace('NOM', 'defsemmi')\n",
    "        if check_macro('PUNCT', window[1]) or check_macro('def_art', window[1]) or re.search('HA', second_right_annot) or check_macro('V', window[1]):\n",
    "            curr_POS = curr_POS.replace('defsemmi', 'semmi')\n",
    "        \n",
    "    return curr_POS\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADJ_rules(window, curr_POS):\n",
    "    first_right_word, first_right_lemma, first_right_annot = window[0]\n",
    "    # print(window)\n",
    "    second_right_word, second_right_lemma, second_right_annot = window[1]\n",
    "    \n",
    "    if check_macro('NUs', window[0]): # if the next token is postposition(al like element), the word gets a 'none'\n",
    "        curr_POS = curr_POS.replace('NOM', 'semmi')\n",
    "    \n",
    "    elif check_macro('not_kop_v', window[0]): # if the next token is a verb, but not a copula, the word is a nominative\n",
    "        curr_POS = curr_POS.replace('NOM', 'nom')\n",
    "    \n",
    "    elif check_macro('szn', window[0]): # before a numeral: default value\n",
    "        curr_POS = curr_POS.replace('NOM', 'nulla')\n",
    "        \n",
    "        if check_macro('PSE', window[1]): # if the second token has a poss. suff.\n",
    "            curr_POS = curr_POS.replace('nulla', 'gen')\n",
    "        else: # otherwise\n",
    "            curr_POS = curr_POS.replace('nulla', 'nom')\n",
    "    \n",
    "    elif check_macro('full_stop', window[0]): # if the next token is a fix outsider, this word must be the end of an NP, thus 'nom'\n",
    "        curr_POS = curr_POS.replace('NOM', 'nom')\n",
    "    \n",
    "    else: # otherwise\n",
    "        curr_POS = curr_POS.replace('NOM', 'defsemmi')\n",
    "        if check_macro('full_stop', window[1]) or check_macro('V', window[1]):# or check_macro('esetragos', window[1]): # if there is a punct.mark in the window\n",
    "            curr_POS = curr_POS.replace('defsemmi', 'semmi')\n",
    "            \n",
    "    return curr_POS    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NOUN_rules(window, curr_POS, curr_word, token):\n",
    "    first_right_word, first_right_lemma, first_right_annot = window[0]\n",
    "    second_right_word, second_right_lemma, second_right_annot = window[1]\n",
    "    if check_macro('NUs', window[0]): # if the next token is postposition(al like element), the word gets a 'none'\n",
    "        curr_POS = curr_POS.replace('NOM', 'semmi')\n",
    "        \n",
    "    elif check_macro('not_gen', token):\n",
    "        curr_POS = curr_POS.replace('NOM', 'nom')\n",
    "        # print('notgen')\n",
    "    \n",
    "    elif check_macro('PSE', window[0]):\n",
    "        curr_POS = curr_POS.replace('NOM', 'gen')\n",
    "        \n",
    "    elif check_macro('not_kop_v', window[0]) or check_macro('pl', window[0]):# or first_right_annot == 'IK':\n",
    "        curr_POS = curr_POS.replace('NOM', 'nom')\n",
    "        # print('notkop')\n",
    "    elif check_macro('TULN', window[0]):\n",
    "        curr_POS = curr_POS.replace('NOM', 'nulla')\n",
    "        \n",
    "        if not check_macro('cimunevu', window[1]):\n",
    "            curr_POS = curr_POS.replace('nulla', 'nom')\n",
    "            # print('cimunevu')\n",
    "    elif check_macro('NPMod', window[0]):\n",
    "        curr_POS = curr_POS.replace('NOM', 'nulla')\n",
    "        # print(\"hurra\")\n",
    "        if check_macro('PSE', window[1]) and not re.search('PSe3', curr_POS):\n",
    "            curr_POS = curr_POS.replace('nulla', 'gen')\n",
    "        elif check_macro('V', window[1]) or check_macro('PUNCT', window[1]) or check_macro('vonatk', window[1]) or re.search('PSe3', curr_POS):\n",
    "            curr_POS = curr_POS.replace('nulla', 'nom')       \n",
    "            # print('V')\n",
    "    elif check_macro('full_stop', window[0]) or first_right_word == ':' or first_right_word == '!':\n",
    "        curr_POS = curr_POS.replace('NOM', 'nom')\n",
    "        # print('fullstop')\n",
    "    else:\n",
    "        curr_POS = curr_POS.replace('NOM', 'nulla')\n",
    "        \n",
    "        if check_macro('V', window[1]) or check_macro('PUNCT', window[1]) or check_macro('vonatk', window[1]) or re.search('PSe3', curr_POS) or second_right_word == \"#\":\n",
    "            curr_POS = curr_POS.replace('nulla', 'nom')       \n",
    "            # print('masoikV')\n",
    "        \n",
    "    return curr_POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nom_or_what(s):\n",
    "    sent = format_sents(s) \n",
    "    new_sent = [] # to store a sentence with the novel tags\n",
    "    to_write_later = [] # to store the NOM token and the window to create the annotation file later\n",
    "    for i in range(len(sent)):\n",
    "        \n",
    "        token = sent[i]\n",
    "        curr_word = token[0]\n",
    "        curr_lemma = token[1]\n",
    "        curr_POS = token[2]\n",
    "        \n",
    "        if curr_word != \"#\": # if the given token is not the end of a sentence\n",
    "        \n",
    "            window = sent[i + 1:i + 3]\n",
    "\n",
    "            \n",
    "            if check_macro('NOM', token): # if the given token is a suffixless nominal\n",
    "                \n",
    "                if check_macro('Noun_tree', token): # if the given token is a noun, or a plural adjective, participle\n",
    "                    curr_POS = NOUN_rules(window, curr_POS, curr_word, token)\n",
    "                    # print(token)\n",
    "\n",
    "                elif check_macro('Adj_tree', token): # if the given token is a singular adjective or participle\n",
    "                    curr_POS = ADJ_rules(window, curr_POS)\n",
    "        \n",
    "                elif check_macro('Num_tree', token): # if the given token is a numeral\n",
    "                    curr_POS = NUM_rules(window, curr_POS)\n",
    "                \n",
    "                new_token = curr_word + ' ' + curr_lemma + ' ' + curr_POS\n",
    "                to_write_later.append( (window, new_token ) ) # a tuple of the window of the given token and the full (novel) annotation of the token\n",
    "                \n",
    "        new_sent.append(curr_word + '/' + curr_lemma + '/' + curr_POS)\n",
    "    \n",
    "    return (new_sent, to_write_later)\n",
    "\n",
    "\n",
    "    # print(' '.join(new_sent))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_annot_file(new_sent, window, outp, i):\n",
    "    outp.writelines(str(i) + '. ' + ' '.join([token.split('/')[0] for token in new_sent])+ '\\n')\n",
    "    [outp.writelines(('-' + nom.split()[0] + ' ' + window[0][0] + ' ' + window[1][0] + '\\n', nom + '\\n', nom + '\\n', nom + '\\n')) for (window, nom) in to_write]\n",
    "    outp.writelines(('\\n', '\\n'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 sent, demo\n",
    "new_sent, to_write = nom_or_what('a/a/DET 20./20./MN.NOM század/század/FN.NOM kiemelkedő/kiemelkedik/IK.IGE._OKEP.NOM irodalmi/irodalmi/MN.NOM egyéniségeit/egyéniség/FN.PSe3i.ACC is/is/HA ././SPUNCT')\n",
    "with open ('egymondat', 'w') as outp:\n",
    "    write_to_annot_file(new_sent,to_write, outp, 1)\n",
    "\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 sents, demo, file\n",
    "with open(input_file, 'r') as inp, open(output_file, 'w') as outp:\n",
    "    for i, line in enumerate(inp, start = 1):\n",
    "        new_sent, to_write = nom_or_what(line)\n",
    "        write_to_annot_file(new_sent, to_write, outp, i)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_annot_with_outp():\n",
    "    annot = open(orig_annot_file, 'r').readlines()\n",
    "    outp = open(output_file, 'r').readlines()\n",
    "    merged_outp = open(merged_output_file, 'w')\n",
    "    print(len(annot))\n",
    "    print(len(outp))\n",
    "    j = -1\n",
    "    for i in range(len(annot)):\n",
    "        if i == j:\n",
    "            merged_outp.write(outp[i])\n",
    "        else:\n",
    "            merged_outp.write(annot[i])\n",
    "        if annot[i].startswith('-'):\n",
    "            j = i+3\n",
    "    merged_outp.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge_annot_with_outp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13286\n",
      "13288\n"
     ]
    }
   ],
   "source": [
    "merge_annot_with_outp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_nom_or_what(annotated_file):\n",
    "    nom_nom = 0\n",
    "    nom_nulla = 0 #falsely underspecified; window-context!\n",
    "    nulla_nom = 0\n",
    "    gen_gen = 0\n",
    "    gen_nulla = 0 #falsely underspecified; window-context!\n",
    "    nulla_nulla = 0 #correctly underspecified; window-context!\n",
    "    nulla_gen = 0\n",
    "    semmi_semmi = 0\n",
    "    defsemmi_defsemmi = 0\n",
    "    defsemmi_semmi = 0\n",
    "    semmi_defsemmi = 0\n",
    "    amnk = 0\n",
    "    other = 0\n",
    "    postag =0\n",
    "    ortho = 0\n",
    "    vok = 0    \n",
    "    full_nom_nom = 0\n",
    "    full_nom_nulla = 0 #falsely underspecified; window-context!\n",
    "    full_nulla_nom = 0\n",
    "    full_gen_gen = 0\n",
    "    full_gen_nulla = 0 #falsely underspecified; window-context!\n",
    "    full_nulla_nulla = 0 #correctly underspecified; window-context!\n",
    "    full_nulla_gen = 0\n",
    "    full_semmi_semmi = 0\n",
    "    full_defsemmi_defsemmi = 0\n",
    "    full_defsemmi_semmi = 0\n",
    "    full_semmi_defsemmi = 0\n",
    "    full_other = 0\n",
    "    full_nom_nom_algo = 0\n",
    "    full_nom_nulla_algo = 0 #falsely underspecified; window-context!\n",
    "    full_nulla_nom_algo = 0\n",
    "    full_gen_gen_algo = 0\n",
    "    full_gen_nulla_algo = 0 #falsely underspecified; window-context!\n",
    "    full_nulla_nulla_algo = 0 #correctly underspecified; window-context!\n",
    "    full_nulla_gen_algo = 0\n",
    "    full_semmi_semmi_algo = 0\n",
    "    full_defsemmi_defsemmi_algo = 0\n",
    "    full_defsemmi_semmi_algo = 0\n",
    "    full_semmi_defsemmi_algo = 0\n",
    "    full_other_algo = 0\n",
    "    # outfile.close()\n",
    "    inf = open(annotated_file, 'r')\n",
    "    for line in inf:\n",
    "        if len(line)>2:\n",
    "            if re.search(\"^[^0-9\\-]\", line.strip()):\n",
    "                # print(line)\n",
    "                annot_manual_full_sent_line = line\n",
    "                annot_manual_full_sent = line.split()[2]\n",
    "                annot_manual_window_line = inf.readline()\n",
    "                annot_manual_window = annot_manual_window_line.strip().split()[2]\n",
    "                annot_automatic_line = inf.readline()\n",
    "                annot_automatic = annot_automatic_line.strip().split()[2]\n",
    "                # print(annot_automatic)\n",
    "                if annot_manual_full_sent.endswith('postag_hiba'):\n",
    "                    postag+=1\n",
    "                elif annot_manual_full_sent.endswith(\"amnk\"):\n",
    "                    amnk+=1\n",
    "                elif annot_manual_full_sent.endswith('vok'):\n",
    "                    vok+= 1\n",
    "                elif annot_manual_full_sent == annot_manual_window:\n",
    "                    if annot_manual_full_sent.endswith(\"nom\"):\n",
    "                        full_nom_nom+= 1\n",
    "                    elif annot_manual_full_sent.endswith(\"gen\"):\n",
    "                        full_gen_gen+=1\n",
    "                    elif annot_manual_full_sent.endswith(\"nulla\"):\n",
    "                        full_nulla_nulla+=1\n",
    "                    elif annot_manual_full_sent.endswith(\"defsemmi\"):\n",
    "                        full_defsemmi_defsemmi+=1\n",
    "                    elif annot_manual_full_sent.endswith(\".semmi\"):\n",
    "                        full_semmi_semmi+=1\n",
    "                else:\n",
    "                    if annot_manual_full_sent.endswith(\"nom\") and annot_manual_window.endswith(\"nulla\"):\n",
    "                        full_nom_nulla+= 1\n",
    "                    elif annot_manual_full_sent.endswith(\"gen\") and annot_manual_window.endswith(\"nulla\"):\n",
    "                        full_gen_nulla+= 1\n",
    "                    elif annot_manual_full_sent.endswith(\"nulla\") and annot_manual_window.endswith(\"nom\"):\n",
    "                        full_nulla_nom+=1\n",
    "                    elif annot_manual_full_sent.endswith(\"nulla\") and annot_manual_window.endswith(\"gen\"):\n",
    "                        full_nulla_gen+=1\n",
    "                    elif annot_manual_full_sent.endswith(\"defsemmi\") and annot_manual_window.endswith(\".semmi\"):\n",
    "                        full_defsemmi_semmi+=1\n",
    "                        # print(annot_manual_full_sent_line + annot_manual_window_line + ' ' + annot_automatic_line)\n",
    "                    elif annot_manual_full_sent.endswith(\".semmi\") and annot_manual_window.endswith(\"defsemmi\"):\n",
    "                        full_semmi_defsemmi+=1\n",
    "                        # print(annot_manual_full_sent_line + annot_manual_window_line + annot_automatic_line)\n",
    "                    elif annot_manual_full_sent.endswith('ortho'):\n",
    "                        ortho+=1\n",
    "                    else:\n",
    "                        # print('full')\n",
    "                        # print(annot_manual_full_sent)\n",
    "                        # print(annot_manual_window)\n",
    "                        full_other+=1\n",
    "                \n",
    "                if annot_manual_window == annot_automatic:\n",
    "                    #ha ugyanazt mondtuk:\n",
    "                    if annot_manual_window.endswith(\"nom\"):\n",
    "                        nom_nom+= 1\n",
    "                    elif annot_manual_window.endswith(\"gen\"):\n",
    "                        gen_gen+=1\n",
    "                    elif annot_manual_window.endswith(\"nulla\"):\n",
    "                        nulla_nulla+=1\n",
    "                    elif annot_manual_window.endswith(\"defsemmi\"):\n",
    "                        defsemmi_defsemmi+=1\n",
    "                    elif annot_manual_window.endswith(\".semmi\"):\n",
    "                        semmi_semmi+=1\n",
    "                 \n",
    "\n",
    "                else:\n",
    "                    if annot_manual_window.endswith(\"nom\") and annot_automatic.endswith(\"nulla\"):\n",
    "                        nom_nulla+= 1\n",
    "                    elif annot_manual_window.endswith(\"gen\") and annot_automatic.endswith(\"nulla\"):\n",
    "                        gen_nulla+= 1\n",
    "                    elif annot_manual_window.endswith(\"nulla\") and annot_automatic.endswith(\"nom\"):\n",
    "                        nulla_nom+=1\n",
    "                    elif annot_manual_window.endswith(\"nulla\") and annot_automatic.endswith(\"gen\"):\n",
    "                        nulla_gen+=1\n",
    "                    elif annot_manual_window.endswith(\"defsemmi\") and annot_automatic.endswith(\".semmi\"):\n",
    "                        defsemmi_semmi+=1\n",
    "                        # print(annot_manual_full_sent_line + annot_manual_window_line + ' ' + annot_automatic_line)\n",
    "                    elif annot_manual_window.endswith(\".semmi\") and annot_automatic.endswith(\"defsemmi\"):\n",
    "                        semmi_defsemmi+=1\n",
    "                        # print(annot_manual_full_sent_line + annot_manual_window_line + annot_automatic_line)\n",
    "                    elif annot_manual_window.endswith('ortho'):\n",
    "                        ortho+=1\n",
    "                    elif annot_manual_full_sent.endswith('postag_hiba'):\n",
    "                        pass\n",
    "                    elif annot_manual_full_sent.endswith(\"amnk\"):\n",
    "                        pass\n",
    "                    elif annot_manual_full_sent.endswith('vok'):\n",
    "                        pass\n",
    "                    else:\n",
    "                        # print(annot_manual_window)\n",
    "                        # print(annot_automatic)\n",
    "                        # print('\\n')\n",
    "                        other+=1\n",
    "                \n",
    "                if annot_manual_full_sent == annot_automatic:\n",
    "                    if annot_manual_full_sent.endswith(\"nom\"):\n",
    "                        full_nom_nom_algo+= 1\n",
    "                    elif annot_manual_full_sent.endswith(\"gen\"):\n",
    "                        full_gen_gen_algo+=1\n",
    "                    elif annot_manual_full_sent.endswith(\"nulla\"):\n",
    "                        full_nulla_nulla_algo+=1\n",
    "                    elif annot_manual_full_sent.endswith(\"defsemmi\"):\n",
    "                        full_defsemmi_defsemmi_algo+=1\n",
    "                    elif annot_manual_full_sent.endswith(\".semmi\"):\n",
    "                        full_semmi_semmi_algo+=1\n",
    "                else:\n",
    "                    if annot_manual_full_sent.endswith(\"nom\") and annot_automatic.endswith(\"nulla\"):\n",
    "                        full_nom_nulla_algo+= 1\n",
    "                    elif annot_manual_full_sent.endswith(\"gen\") and annot_automatic.endswith(\"nulla\"):\n",
    "                        full_gen_nulla_algo+= 1\n",
    "                    elif annot_manual_full_sent.endswith(\"nulla\") and annot_automatic.endswith(\"nom\"):\n",
    "                        full_nulla_nom_algo+=1\n",
    "                    elif annot_manual_full_sent.endswith(\"nulla\") and annot_automatic.endswith(\"gen\"):\n",
    "                        full_nulla_gen_algo+=1\n",
    "                    elif annot_manual_full_sent.endswith(\"defsemmi\") and annot_automatic.endswith(\".semmi\"):\n",
    "                        full_defsemmi_semmi_algo+=1\n",
    "                        # print(annot_manual_full_sent_line + annot_manual_window_line + ' ' + annot_automatic_line)\n",
    "                    elif annot_manual_full_sent.endswith(\".semmi\") and annot_automatic.endswith(\"defsemmi\"):\n",
    "                        full_semmi_defsemmi_algo+=1\n",
    "                        # print(annot_manual_full_sent_line + annot_manual_window_line + annot_automatic_line)\n",
    "                    elif annot_manual_full_sent.endswith('ortho'):\n",
    "                        ortho+=1\n",
    "                    else:\n",
    "                        # print('full')\n",
    "                        # print(annot_manual_full_sent)\n",
    "                        # print(annot_manual_window)\n",
    "                        full_other_algo+=1\n",
    "               \n",
    " \n",
    "    \n",
    "    print(\"full_nom_nom = \" + str(full_nom_nom))\n",
    "    print(\"full_gen_gen = \" + str(full_gen_gen))\n",
    "    print(\"full_nulla_nulla = \" + str(full_nulla_nulla))\n",
    "    print(\"full_semmi_semmi = \" + str(full_semmi_semmi))\n",
    "    print(\"full_defsemmi_defsemmi = \" + str(full_defsemmi_defsemmi))\n",
    "    print(\"full_nulla_nom = \" + str(full_nulla_nom))\n",
    "    print(\"full_nulla_gen = \" + str(full_nulla_gen))\n",
    "    print(\"full_defsemmi_semmi = \" + str(full_defsemmi_semmi))\n",
    "    print(\"full_nom_nulla = \" + str(full_nom_nulla)) \n",
    "    print(\"full_gen_nulla = \" + str(full_gen_nulla))\n",
    "    print(\"full_semmi_defsemmi = \" + str(full_semmi_defsemmi))\n",
    "    print(\"full_other = \" + str(full_other))\n",
    "    print()\n",
    "    print()\n",
    "    print(\"nom_nom = \" + str(nom_nom))\n",
    "    print(\"gen_gen = \" + str(gen_gen))\n",
    "    print(\"nulla_nulla = \" + str(nulla_nulla))\n",
    "    print(\"semmi_semmi = \" + str(semmi_semmi))\n",
    "    print(\"defsemmi_defsemmi = \" + str(defsemmi_defsemmi))\n",
    "    print(\"nulla_nom = \" + str(nulla_nom))\n",
    "    print(\"nulla_gen = \" + str(nulla_gen))\n",
    "    print(\"defsemmi_semmi = \" + str(defsemmi_semmi))\n",
    "    print(\"nom_nulla = \" + str(nom_nulla)) \n",
    "    print(\"gen_nulla = \" + str(gen_nulla))\n",
    "    print(\"semmi_defsemmi = \" + str(semmi_defsemmi))\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"amnk = \" + str(amnk))\n",
    "    print(\"postag = \" + str(postag))\n",
    "    print(\"egyéb = \" + str(other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_nom_nom = 626\n",
      "full_gen_gen = 266\n",
      "full_nulla_nulla = 17\n",
      "full_semmi_semmi = 762\n",
      "full_defsemmi_defsemmi = 6\n",
      "full_nulla_nom = 0\n",
      "full_nulla_gen = 0\n",
      "full_defsemmi_semmi = 0\n",
      "full_nom_nulla = 187\n",
      "full_gen_nulla = 54\n",
      "full_semmi_defsemmi = 397\n",
      "full_other = 31\n",
      "\n",
      "\n",
      "nom_nom = 621\n",
      "gen_gen = 257\n",
      "nulla_nulla = 248\n",
      "semmi_semmi = 623\n",
      "defsemmi_defsemmi = 366\n",
      "nulla_nom = 19\n",
      "nulla_gen = 4\n",
      "defsemmi_semmi = 42\n",
      "nom_nulla = 13\n",
      "gen_nulla = 4\n",
      "semmi_defsemmi = 131\n",
      "amnk = 42\n",
      "postag = 128\n",
      "egyéb = 21\n"
     ]
    }
   ],
   "source": [
    "evaluate_nom_or_what(\"test_1000_merged_output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
